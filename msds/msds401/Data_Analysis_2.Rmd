---
title: "Data Analysis Assignment #2 (75 points total)"
author: "lastName, firstName"
output:
  html_document: default
---

```{r setup, include = FALSE}
# DO NOT ADD OR REVISE CODE HERE
knitr::opts_chunk$set(echo = FALSE, eval = TRUE)

```

### Instructions

R markdown is a plain-text file format for integrating text and R code, and creating transparent, reproducible and interactive reports. An R markdown file (.Rmd) contains metadata, markdown and R code "chunks", and can be "knit" into numerous output types. Answer the test questions by adding R code to the fenced code areas below each item. There are questions that require a written answer that also need to be answered. Enter your comments in the space provided as shown below:

***Answer: (Enter your answer here.)*** 

Once completed, you will "knit" and submit the resulting .html document and the .Rmd file. The .html will present the output of your R code and your written answers, but your R code will not appear.  Your R code will appear in the .Rmd file. The resulting .html document will be graded and a feedback report returned with comments.  Points assigned to each item appear in the template.

**Before proceeding, look to the top of the .Rmd for the (YAML) metadata block, where the *title*, *author* and *output* are given. Please change *author* to include your name, with the format 'lastName, firstName.'**

If you encounter issues with knitting the .html, please send an email via Canvas to your TA.

Each code chunk is delineated by six (6) backticks; three (3) at the start and three (3) at the end. After the opening ticks, arguments are passed to the code chunk and in curly brackets. **Please do not add or remove backticks, or modify the arguments or values inside the curly brackets**. An example code chunk is included here: 

```{r exampleCodeChunk, eval = FALSE, echo = TRUE}
# Comments are included in each code chunk, simply as prompts

#...R code placed here

#...R code placed here

```

R code only needs to be added inside the code chunks for each assignment item. However, there are questions that follow many assignment items. Enter your answers in the space provided. An example showing how to use the template and respond to a question follows.

-----

**Example Problem with Solution:**

Use *rbinom()* to generate two random samples of size 10,000 from the binomial distribution. For the first sample, use p = 0.45 and n = 10. For the second sample, use p = 0.55 and n = 10. Convert the sample frequencies to sample proportions and compute the mean number of successes for each sample. Present these statistics.

```{r Example, eval = TRUE, echo = TRUE}

set.seed(123)
sample.one <- table(rbinom(10000, 10, 0.45)) / 10000
sample.two <- table(rbinom(10000, 10, 0.55)) / 10000

successes <- seq(0, 10)

round(sum(sample.one*successes), digits = 1) # [1] 4.5
round(sum(sample.two*successes), digits = 1) # [1] 5.5
```

**Question: How do the simulated expectations compare to calculated binomial expectations?**

***Answer:  The calculated binomial expectations are 10(0.45) = 4.5 and 10(0.55) = 5.5.  After rounding the simulated results, the same values are obtained.***

-----

Submit both the .Rmd and .html files for grading. You may remove the instructions and example problem above, but do not remove the YAML metadata block or the first, "setup" code chunk.  Address the steps that appear below and answer all the questions. Be sure to address each question with code and comments as needed.  You may use either base R functions or ggplot2 for the visualizations.

-----

##Data Analysis #2

```{r analysis_setup1, message = FALSE, warning = FALSE}

# Perform the following steps to start the assignment.
 
# 1) Load/attach the following packages via library():  flux, ggplot2, gridExtra, moments, rockchalk, car.
# NOTE:  packages must be installed via install.packages() before they can be loaded.

library(dplyr)
library(flux)
library(ggplot2)
library(gridExtra)
library(knitr)
library(rockchalk)
library(tidyverse)

# 2) Use the "mydata.csv" file from Assignment #1 or use the file posted on the course site.  Reading
# the files into R will require sep = "" or sep = " " to format data properly.  Use str() to check file
# structure.

dat <- read.csv("data/abalones.csv", sep = ",", stringsAsFactors = TRUE)
# mydata <- read.csv(file.path("c:...", "mydata.csv"), sep = ",")
# mydata <- read.csv(file.path("c:/Rabalone/", "mydata.csv"), sep = ",")

dat$VOLUME <- dat$LENGTH * dat$DIAM * dat$HEIGHT
dat$RATIO <- dat$SHUCK / dat$VOLUME

```

### Test Items starts from here - There are 10 sections - total of 75 points ##############

***#### Section 1: (5 points) ####***

(1)(a) Form a histogram and QQ plot using RATIO. Calculate skewness and kurtosis using 'rockchalk.' Be aware that with 'rockchalk', the kurtosis value has 3.0 subtracted from it which differs from the 'moments' package. 

```{r Part_1a, fig.width = 12}
kurt = rockchalk::kurtosis(dat$RATIO)
skew = rockchalk::skewness(dat$RATIO)

p1 = ggplot(dat, aes(RATIO)) + 
  geom_histogram() + 
  labs(title=sprintf("Ratio histogram | Kurtosis %s | Skewness %s", round(kurt, 2), round(skew, 2)))
p2 = ggplot(dat, aes(sample=RATIO)) + 
  geom_qq() + 
  geom_qq_line() + 
  labs(title=sprintf("Normality test for RATIO | Kurtosis %s | Skewness %s", round(kurt, 2), round(skew, 2)))

#grid.arrange(p1, p2)

p3 = ggplot(dat, aes(RATIO)) + 
  geom_histogram() + 
  labs(title=sprintf("Ratio histogram by class")) + 
  facet_grid(~CLASS)
p4 = ggplot(dat, aes(sample=RATIO)) + 
  geom_qq() + 
  geom_qq_line() + 
  labs(title=sprintf("Normality test for RATIO by class")) + 
  facet_grid(~CLASS)

grid.arrange(p1, p2, p3, p4)

```

(1)(b) Tranform RATIO using *log10()* to create L_RATIO (Kabacoff Section 8.5.2, p. 199-200). Form a histogram and QQ plot using L_RATIO. Calculate the skewness and kurtosis. Create a boxplot of L_RATIO differentiated by CLASS.

```{r Part_1b, fig.width = 12, fig.height = 8}

dat$L_RATIO <- log10(dat$RATIO)

kurt = rockchalk::kurtosis(dat$L_RATIO)
skew = rockchalk::skewness(dat$L_RATIO)

p1 = ggplot(dat, aes(L_RATIO)) + geom_histogram() + labs(title=sprintf("Log(RATIO) histogram | Kurtosis %s | Skewness %s", round(kurt, 2), round(skew, 2)))
p2 = ggplot(dat, aes(sample=L_RATIO)) + geom_qq() + geom_qq_line() + labs(title=sprintf("Normality test for Log(RATIO) | Kurtosis %s | Skewness %s", round(kurt, 2), round(skew, 2)))
#grid.arrange(p1, p2)

p3 = ggplot(dat, aes(L_RATIO)) + 
  geom_histogram() + 
  labs(title=sprintf("Log(RATIO) histogram by class")) + 
  facet_grid(~CLASS)
p4 = ggplot(dat, aes(sample=L_RATIO)) + 
  geom_qq() + 
  geom_qq_line() + 
  labs(title=sprintf("Normality test for Log(RATIO) by class")) + 
  facet_grid(~CLASS)

p5 = ggplot(dat, aes(x=CLASS, y=L_RATIO)) +
  geom_boxplot()

grid.arrange(p1, p2, p3, p4, p5, layout_matrix=rbind(c(1,1,2,2), c(3,3,4,4), c(5,5,5,5), c(5,5,5,5)))

```

(1)(c) Test the homogeneity of variance across classes using *bartlett.test()* (Kabacoff Section 9.2.2, p. 222). 

```{r Part_1c}

print(bartlett.test(RATIO ~ CLASS, dat))
print(bartlett.test(L_RATIO ~ CLASS, dat))
```

**Essay Question: Based on steps 1.a, 1.b and 1.c, which variable RATIO or L_RATIO exhibits better conformance to a normal distribution with homogeneous variances across age classes?  Why?** 

You can see difference in variances when comparing the histograms of RATIO between each classes. When comparing the histograms of log-RATIO there seems to be a more consistent variance behavior.

This intuition is confirmed with Barlett's test. Non-log RATIO variances by class have a p-value low enough to reject the homogeneous variance hypothesis for reasonable confidence levels (i.e. 99% confident). On the other hand, the p-value of the log-RATIO variances by class do not have a very small p-value (only 0.52) which suggest we should continue with the hypothesis that log-RATIO values have equal variances across different age classes.

***#### Section 2 (10 points) ####***

(2)(a) Perform an analysis of variance with *aov()* on L_RATIO using CLASS and SEX as the independent variables (Kabacoff chapter 9, p. 212-229). Assume equal variances. Perform two analyses. First, fit a model with the interaction term CLASS:SEX. Then, fit a model without CLASS:SEX. Use *summary()* to obtain the analysis of variance tables (Kabacoff chapter 9, p. 227).

```{r Part_2a}
aov.results = aov(L_RATIO ~ CLASS + SEX, data = dat)
print(summary(aov.results))
aov.results.interaction = aov(L_RATIO ~ CLASS*SEX, data = dat)
print(summary(aov.results.interaction))
```

**Essay Question:  Compare the two analyses.  What does the non-significant interaction term suggest about the relationship between L_RATIO and the factors CLASS and SEX?**

The `aov` test above are checking whether or not the variance in `CLASS` or `SEX` can explain the variance in `L_RATIO` (which is a measurement of meat per cubic centimeter of abalone volume). The small p-values for both `CLASS` and `SEX` suggest that `L_RATIO` is effected by changes in both `CLASS` and `SEX`, indicating we may be able to use `CLASS` and `SEX` as predictors for a abalone meat density.


(2)(b) For the model without CLASS:SEX (i.e. an interaction term), obtain multiple comparisons with the *TukeyHSD()* function. Interpret the results at the 95% confidence level (*TukeyHSD()* will adjust for unequal sample sizes). 

```{r Part_2b}
library(kableExtra)
tukey.results = TukeyHSD(aov.results)
plot(tukey.results , las=1 , col="brown")
```

**Additional Essay Question:  first, interpret the trend in coefficients across age classes. What is this indicating about L_RATIO?  Second, do these results suggest male and female abalones can be combined into a single category labeled as 'adults?' If not, why not?**

When you compare two age classes, the difference in means seems to grow as the age classes get further apart. For example, the age classes with the largest difference in `L_RATIO` means are the `A1` and `A5`, followed up by `A5` and `A2`). Age classes closer together (i.e. `A1`/`A2`, `A2`/`A3`, `A3`/`A4`, and `A4`/`A5`) show mean differences that are closer to 0 than all other age class comparisons.

The second family-wise chart is comparing the `L_RATIO` of the difference sexes. The difference in means between `M` and `F` abalones is close to zero, as indicated by its center mark being near the dotted line. This lends to the suggestion that we might want to combine the those two geneders into a single class.

***####  Section 3: (10 points) ####***

(3)(a1) Here, we will combine "M" and "F" into a new level, "ADULT". The code for doing this is given to you. For (3)(a1), all you need to do is execute the code as given.

```{r Part_3a1}
# Here, we show how to define the new variable TYPE using only base R functions:

dat$TYPE <- factor(ifelse(dat$SEX == "I", "INFANT", "ADULT"))
table(dat$TYPE)


```

(3)(a2)  Present side-by-side histograms of VOLUME. One should display infant volumes and, the other, adult volumes. 

```{r Part_3a2, fig.width = 12}
p1 = ggplot(dat, aes(x=VOLUME)) + 
  geom_histogram() + 
  facet_grid(~TYPE) +
  labs(title=sprintf("Histogram of Volume for both Adult and Infant abalones"), x="Volume (cc)")
p2 = ggplot(dat, aes(sample=VOLUME)) + 
  geom_qq() + 
  geom_qq_line() + 
  facet_grid(~TYPE) +
  labs(title=sprintf("QQ Plot of Volume for both Adult and Infant abalones"), x="Volume (cc)")

p3 = ggplot(dat, aes(x=VOLUME, y=TYPE)) + 
  geom_boxplot() + 
  labs(title=sprintf("Boxplots of Volume for both Adult and Infant abalones"), x="Volume (cc)")

grid.arrange(p1, p2, p3)
```


The adult distribution is more normal than the infants'. The infant abalones have a right skew, which makes sense given that they are younger and thus more concentrated near the smaller volumes. The box-plots shows that the IRQ of the two types (`ADULT` and `INFANT`) do not overlap. This separation may allow us to separate the two groups with a useful degree of certainty. Where the two groups' IQRs almost overlap (the 250 cc volume mark) we will need to see if there is another way to separate the two groups.

***Answer: (Enter your answer here.)***

(3)(b) Create a scatterplot of SHUCK versus VOLUME and a scatterplot of their base ten logarithms, labeling the variables as L_SHUCK and L_VOLUME. Please be aware the variables, L_SHUCK and L_VOLUME, present the data as orders of magnitude (i.e. VOLUME = 100 = 10^2 becomes L_VOLUME = 2). Use color to differentiate CLASS in the plots. Repeat using color to differentiate by TYPE. 

```{r Part_3b, fig.width = 12, fig.height = 8}
p1 = ggplot(dat, aes(x=SHUCK, y=VOLUME, color=CLASS)) +
  labs(title=sprintf("Scatterplot of SHUCK vs VOLUME"), x="SHUCK (g)", y="VOLUME (cc)") +
  geom_point()

dat$L_SHUCK = log(dat$SHUCK)
dat$L_VOLUME = log(dat$VOLUME)
p2 = ggplot(dat, aes(x=L_SHUCK, y=L_VOLUME, color=CLASS)) +
  labs(title=sprintf("Scatterplot of log(SHUCK) vs log(VOLUME)"), x="log SHUCK (g)", y="log VOLUME (cc)") +
  geom_point()
grid.arrange(p1, p2)

p3 = ggplot(dat, aes(x=SHUCK, y=VOLUME, color=TYPE)) +
  labs(title=sprintf("Scatterplot of SHUCK vs VOLUME"), x="SHUCK (g)", y="VOLUME (cc)") +
  geom_point()

p4 = ggplot(dat, aes(x=L_SHUCK, y=L_VOLUME, color=TYPE)) +
  labs(title=sprintf("Scatterplot of log(SHUCK) vs log(VOLUME)"), x="log SHUCK (g)", y="log VOLUME (cc)") +
  geom_point()
grid.arrange(p3, p4)
```

**Additional Essay Question:  Compare the two scatterplots. What effect(s) does log-transformation appear to have on the variability present in the plot?  What are the implications for linear regression analysis? Where do the various CLASS levels appear in the plots? Where do the levels of TYPE appear in the plots?**

The log transformation for both the `TYPE` and `CLASS` types would reduce the sum of square error for a hypothetical regression line. With the `CLASS` charts, when we look at `L_VOLUME` and `L_SHUCK` the `A1` age class seems to get pushed away from the mass of other values -- this could help us during classification. Because the other classes are grouped together this suggests that abalone growth slows after reaching the more advanced age classes.

The log plot for `TYPE` on the other hand is not so helpful. The regression does get tighter, but the two gender types become much more intermingled when we apply the log transform to `VOLUME` and `SHUCK`.

***####   Section 4: (5 points) ####***

(4)(a1) Since abalone growth slows after class A3, infants in classes A4 and A5 are considered mature and candidates for harvest. You are given code in (4)(a1) to reclassify the infants in classes A4 and A5 as ADULTS. 

```{r Part_4a1}

dat$TYPE[dat$CLASS == "A4" | dat$CLASS == "A5"] <- "ADULT"
table(dat$TYPE)

```

(4)(a2) Regress L_SHUCK as the dependent variable on L_VOLUME, CLASS and TYPE (Kabacoff Section 8.2.4, p. 178-186, the Data Analysis Video #2 and Black Section 14.2). Use the multiple regression model: L_SHUCK ~ L_VOLUME + CLASS + TYPE. Apply *summary()* to the model object to produce results.

```{r Part_4a2}
model = lm(L_SHUCK ~ L_VOLUME + CLASS + TYPE, dat)
summary(model)
model = lm(L_SHUCK ~ L_VOLUME + CLASS, dat)
summary(model)
```

**Essay Question:  Interpret the trend in CLASS levelcoefficient estimates? (Hint:  this question is not asking if the estimates are statistically significant. It is asking for an interpretation of the pattern in these coefficients, and how this pattern relates to the earlier displays).**

The trend seems to be that as class increases (from 2 to 5) so too does the magnitude of the coefficient. This aligns with the previous charts as it indicates that as class goes up so too does `SHUCK` weight.


**Additional Essay Question:  Is TYPE an important predictor in this regression? (Hint:  This question is not asking if TYPE is statistically significant, but rather how it compares to the other independent variables in terms of its contribution to predictions of L_SHUCK for harvesting decisions.)  Explain your conclusion.**

`TYPE` is not an important predictor for meat content. While `TYPE` does contain _some_ predictive power, its coefficient is nearly five times as small as the class `A5`'s predictive contribution. If we take `TYPE` out of our model and rerun it, the adjusted R-squared value (which accounts for adding and removing predictors) goes from 0.9501 to 0.9498 (meaning that `TYPE` only contributed to 0.0003 to improving the R value).
-----

The next two analysis steps involve an analysis of the residuals resulting from the regression model in (4)(a) (Kabacoff Section 8.2.4, p. 178-186, the Data Analysis Video #2).

-----

***#### Section 5: (5 points) ####***

(5)(a) If "model" is the regression object, use model$residuals and construct a histogram and QQ plot. Compute the skewness and kurtosis. Be aware that with 'rockchalk,' the kurtosis value has 3.0 subtracted from it which differs from the 'moments' package. 

```{r Part_5am, fig.width = 12}
dat$m1_residuals = model$residuals

kurt = rockchalk::kurtosis(model$residuals)
skew = rockchalk::skewness(model$residuals)


p1 = ggplot(rmodel, aes(residuals)) + geom_histogram() + labs(title=sprintf("Residuals histogram | Kurtosis %s | Skewness %s", round(kurt, 2), round(skew, 2)))
p2 = ggplot(rmodel, aes(sample=residuals)) + 
  geom_qq() + 
  geom_qq_line() +
  labs(title="QQ plot of residuals")
  geom_qq_line()
  
grid.arrange(p1, p2)
```

(5)(b) Plot the residuals versus L_VOLUME, coloring the data points by CLASS and, a second time, coloring the data points by TYPE. Keep in mind the y-axis and x-axis may be disproportionate which will amplify the variability in the residuals. Present boxplots of the residuals differentiated by CLASS and TYPE (These four plots can be conveniently presented on one page using *par(mfrow..)* or *grid.arrange()*. Test the homogeneity of variance of the residuals across classes using *bartlett.test()* (Kabacoff Section 9.3.2, p. 222).  

```{r Part_5b, fig.width = 12, fig.height = 8}
p1 = ggplot(dat) + 
  geom_point(aes(x=L_VOLUME, y=m1_residuals, color=CLASS)) +
  labs(title="Scatterplot of model residuals vs log(Volume) | Colored by Class", y="Residuals", x="log(Volume)") +
  geom_abline(intercept = 0, slope=0, color='black')
p2 = ggplot(dat) + 
  geom_point(aes(x=L_VOLUME, y=m1_residuals, color=TYPE)) +
  labs(title="Scatterplot of model residuals vs log(Volume) | Colored by Type", y="Residuals", x="log(Volume)") +
  geom_abline(intercept = 0, slope=0, color='black')
p3 = ggplot(dat) +
  labs(title="Boxplots of residuals by class", y="Residuals") +
  geom_boxplot(aes(x=CLASS, y=m1_residuals))
p4 = ggplot(dat) +
  labs(title="Boxplots of residuals by type", y="Residuals") +
  geom_boxplot(aes(x=TYPE, y=m1_residuals))

grid.arrange(p1, p2, p3, p4, layout_matrix=rbind(
  c(1,1,2,2),
  c(1,1,2,2),
  c(3,3,4,4),
  c(3,3,4,4)
))
```

```{r}
print(bartlett.test(m1_residuals ~ CLASS, dat))
print(bartlett.test(m1_residuals ~ TYPE, dat))
```

**Essay Question:  What is revealed by the displays and calculations in (5)(a) and (5)(b)? Does the model 'fit'?  Does this analysis indicate that L_VOLUME, and ultimately VOLUME, might be useful for harvesting decisions? Discuss.**  

The mean residual for all `CLASS` and `TYPE` instances seem to be centered around zero and appear to be normally distributed. Confirming this is the Bartlett test which has a high p-value, leading us to support the hypothesis that the variance of residuals is homogeneous.

What this means is that for predictions of `SHUCK` we can expect the error contributed by an abalone's `VOLUME` to be normally distributed across all predictions. This is useful because we can quantify how incorrect our prediction may be by using the normal curve. If we can quantify the error we can set limits that ensure we stay above a certain level of error most of the time.

-----

Harvest Strategy:

There is a tradeoff faced in managing abalone harvest. The infant population must be protected since it represents future harvests. On the other hand, the harvest should be designed to be efficient with a yield to justify the effort. This assignment will use VOLUME to form binary decision rules to guide harvesting. If VOLUME is below a "cutoff" (i.e. a specified volume), that individual will not be harvested. If above, it will be harvested. Different rules are possible.The Management needs to make a decision to implement 1 rule that meets the business goal.

The next steps in the assignment will require consideration of the proportions of infants and adults harvested at different cutoffs. For this, similar "for-loops" will be used to compute the harvest proportions. These loops must use the same values for the constants min.v and delta and use the same statement "for(k in 1:10000)."  Otherwise, the resulting infant and adult proportions cannot be directly compared and plotted as requested. Note the example code supplied below.

-----

***#### Section 6: (5 points) ####***

(6)(a) A series of volumes covering the range from minimum to maximum abalone volume will be used in a "for loop" to determine how the harvest proportions change as the "cutoff" changes. Code for doing this is provided.

```{r Part_6a}

idxi <- dat$TYPE == "INFANT"
idxa <- dat$TYPE == "ADULT"

max.v <- max(dat$VOLUME)
min.v <- min(dat$VOLUME)
delta <- (max.v - min.v)/10000
prop.infants <- numeric(10000)
prop.adults <- numeric(10000)
volume.value <- numeric(10000)

total.infants <- sum(idxi)  
total.adults <- sum(idxa)

for (k in 1:10000) { 
	value <- min.v + k*delta
	volume.value[k] <- value
	prop.infants[k] <- sum(dat$VOLUME[idxi] <= value)/total.infants
	prop.adults[k] <-  sum(dat$VOLUME[idxa] <= value)/total.adults
}
```

(6)(b) Our first "rule" will be protection of all infants. We want to find a volume cutoff that protects all infants, but gives us the largest possible harvest of adults. We can achieve this by using the volume of the largest infant as our cutoff. You are given code below to identify the largest infant VOLUME and to return the proportion of adults harvested by using this cutoff. You will need to modify this latter code to return the proportion of infants harvested using this cutoff. Remember that we will harvest any individual with VOLUME greater than our cutoff.

```{r Part_6b}
# Largest infant volume
(max_inf_vol <- max(dat$VOLUME[dat$TYPE == "INFANT"]))  # [1] 526.6383

# Proportion of adults harvested
sum(dat$VOLUME[dat$TYPE == "ADULT"] > max_inf_vol) /
  total.adults  # [1] 0.2476573

# Add code to calculate the proportion of infants harvested
sum(dat$VOLUME[dat$TYPE == "INFANT"] > max_inf_vol) / total.infants

# If we use the largest infant volume, we harvest approximately 24.8% of adults and 0%,
# as expected, of infants.

```

(6)(c) Our next approaches will look at what happens when we use the median infant and adult harvest VOLUMEs. Using the median VOLUMEs as our cutoffs will give us (roughly) 50% harvests. We need to identify the median volumes and calculate the resulting infant and adult harvest proportions for both.

```{r Part_6c}
# Add code to determine the median infant volume:
median_inf_vol <- median(dat$VOLUME[dat$TYPE == "INFANT"]) 


# Add code to calculate the proportion of infants harvested
sum(dat$VOLUME[dat$TYPE == "INFANT"] > median_inf_vol) / total.infants


# Add code to calculate the proportion of adults harvested
sum(dat$VOLUME[dat$TYPE == "ADULT"] > median_inf_vol) / total.adults

# If we use the median infant volume as our cutoff, we harvest almost 50% of our infants
# and a little more than 93% of our adults.


# Add code to determine the median adult volume:
median_adult_vol <- median(dat$VOLUME[dat$TYPE == "ADULT"]) 

# Add code to calculate the proportion of infants harvested
sum(dat$VOLUME[dat$TYPE == "INFANT"] > median_adult_vol) / total.infants


# Add code to calculate the proportion of adults harvested
sum(dat$VOLUME[dat$TYPE == "ADULT"] > median_adult_vol) / total.adults


# If we use the median adult volume as our cutoff, we harvest almost 50% of adults
# and approximately 2.4% of infants.

```

(6)(d) Next, we will create a plot showing the infant conserved proportions (i.e. "not harvested," the prop.infants vector) and the adult conserved proportions (i.e. prop.adults) as functions of volume.value. We will add vertical A-B lines and text annotations for the three (3) "rules" considered, thus far:  "protect all infants," "median infant" and "median adult." Your plot will have two (2) curves - one (1) representing infant and one (1) representing adult proportions as functions of volume.value - and three (3) A-B lines representing the cutoffs determined in (6)(b) and (6)(c).

```{r Part_6d, fig.width = 12, fig.height = 6}
pdf = data.frame(
  prop = c(prop.infants,  prop.adults),
  TYPE = c(rep('INFANT', length(prop.infants)), rep('ADULT', length(prop.adults))),
  volume.value = volume.value
)
ggplot(pdf) + 
  geom_step(aes(x=volume.value, y=prop, group=TYPE, color=TYPE)) + 
  geom_vline(aes(xintercept=median_adult_vol)) +
  geom_text(aes(x=median_adult_vol, label="\nthe strong cars", y=0), colour="blue", angle=90) +
  geom_vline(aes(xintercept=median_inf_vol)) + 
  geom_hline(aes(yintercept=0.50))
```

**Essay Question:  The two 50% "median" values serve a descriptive purpose illustrating the difference between the populations. What do these values suggest regarding possible cutoffs for harvesting?** 

***Answer: (Enter your answer here.)***

-----


More harvest strategies:

This part will address the determination of a cutoff volume.value corresponding to the observed maximum difference in harvest percentages of adults and infants. In other words, we want to find the volume value such that the vertical distance between the infant curve and the adult curve is maximum. To calculate this result, the vectors of proportions from item (6) must be used. These proportions must be converted from "not harvested" to "harvested" proportions by using (1 - prop.infants) for infants, and (1 - prop.adults) for adults. The reason the proportion for infants drops sooner than adults is that infants are maturing and becoming adults with larger volumes.

-----

***#### Section 7: (10 points)  ####***

(7)(a) Evaluate a plot of the difference ((1 - prop.adults) - (1 - prop.infants)) versus volume.value. Compare to the 50% "split" points determined in (6)(a). There is considerable variability present in the peak area of this plot. The observed "peak" difference may not be the best representation of the data. One solution is to smooth the data to determine a more representative estimate of the maximum difference.

```{r Part_7a}


```

(7)(b) Since curve smoothing is not studied in this course, code is supplied below. Execute the following code to create a smoothed curve to append to the plot in (a). The procedure is to individually smooth (1-prop.adults) and (1-prop.infants) before determining an estimate of the maximum difference. 

```{r Part_7b}

y.loess.a <- loess(1 - prop.adults ~ volume.value, span = 0.25,
	family = c("symmetric"))
y.loess.i <- loess(1 - prop.infants ~ volume.value, span = 0.25,
	family = c("symmetric"))
smooth.difference <- predict(y.loess.a) - predict(y.loess.i)

```

(7)(c) Present a plot of the difference ((1 - prop.adults) - (1 - prop.infants)) versus volume.value with the variable smooth.difference superimposed. Determine the volume.value corresponding to the maximum smoothed difference (Hint:  use *which.max()*). Show the estimated peak location corresponding to the cutoff determined.

Include, side-by-side, the plot from (6)(d) but with a fourth vertical A-B line added. That line should intercept the x-axis at the "max difference" volume determined from the smoothed curve here.

```{r Part_7c, fig.width = 12, fig.height = 6}


```

(7)(d) What separate harvest proportions for infants and adults would result if this cutoff is used? Show the separate harvest proportions. We will actually calculate these proportions in two ways:  first, by 'indexing' and returning the appropriate element of the (1 - prop.adults) and (1 - prop.infants) vectors, and second, by simply counting the number of adults and infants with VOLUME greater than the vlume threshold of interest.

Code for calculating the adult harvest proportion using both approaches is provided.

```{r Part_7d}

(1 - prop.adults)[which.max(smooth.difference)]  # [1] 0.7416332
# OR,
sum(mydata[mydata$TYPE == "ADULT", "VOLUME"] >
      volume.value[which.max(smooth.difference)]) / total.adults # [1] 0.7416332

```

-----

There are alternative ways to determine cutoffs. Two such cutoffs are described below.

-----

***####  Section 8: (10 points)  ####***

(8)(a) Harvesting of infants in CLASS "A1" must be minimized. The smallest volume.value cutoff that produces a zero harvest of infants from CLASS "A1" may be used as a baseline for comparison with larger cutoffs. Any smaller cutoff would result in harvesting infants from CLASS "A1."  

Compute this cutoff, and the proportions of infants and adults with VOLUME exceeding this cutoff. Code for determining this cutoff is provided. Show these proportions. You may use either the 'indexing' or 'count' approach, or both.

```{r Part_8a}

volume.value[volume.value > max(mydata[mydata$CLASS == "A1" &
  mydata$TYPE == "I", "VOLUME"])][1] # [1] 206.786

```

(8)(b) Next, append one (1) more vertical A-B line to our (6)(d) graph. This time, showing the "zero A1 infants" cutoff from (8)(a). This graph should now have five (5) A-B lines:  "protect all infants," "median infant," "median adult," "max difference" and "zero A1 infants."

```{r Part_8b, fig.width = 12}


```


***#### Section 9: (5 points) ####***

(9)(a) Construct an ROC curve by plotting (1 - prop.adults) versus (1 - prop.infants). Each point which appears corresponds to a particular volume.value. Show the location of the cutoffs determined in (6), (7) and (8) on this plot and label each. 

```{r Part_9, fig.width = 8.5}


```

(9)(b) Numerically integrate the area under the ROC curve and report your result. This is most easily done with the *auc()* function from the "flux" package.   Areas-under-curve, or AUCs, greater than 0.8 are taken to indicate good discrimination potential. 

```{r Part_9b}


```


***#### Section 10: (10 points) ####***

(10)(a) Prepare a table showing each cutoff along with the following:
 	1) true positive rate (1-prop.adults,
 	2) false positive rate (1-prop.infants),
 	3) harvest proportion of the total population

To calculate the total harvest proportions, you can use the 'count' approach, but ignoring TYPE; simply count the number of individuals (i.e. rows) with VOLUME greater than a given threshold and divide by the total number of individuals in our dataset.
 	
```{r Part_10} 	


```
 	
**Essay Question: Based on the ROC curve, it is evident a wide range of possible "cutoffs" exist. Compare and discuss the five cutoffs determined in this assignment.**   

***Answer: (Enter your answer here.)***



**Final Essay Question:  Assume you are expected to make a presentation of your analysis to the investigators How would you do so?  Consider the following in your answer:**

1. Would you make a specific recommendation or outline various choices and tradeoffs?
2. What qualifications or limitations would you present regarding your analysis?
3. If it is necessary to proceed based on the current analysis, what suggestions would you have for  implementation of a cutoff?  
4. What suggestions would you have for planning future abalone studies of this type? 

***Answer: (Enter your answer here.)***